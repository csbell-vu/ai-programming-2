{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e4a8697-72d1-4e62-adf8-fe7f8332fef9",
   "metadata": {},
   "source": [
    "# AI-Assisted Programming\n",
    "> Huggingface Transformers and OpenAI\n",
    "\n",
    "Leveraging packages for solutions\n",
    "\n",
    "## Class Overview\n",
    "* Quick review of Gradio\n",
    "* Huggingface Transformers\n",
    "  * Inference\n",
    "  * Tasks\n",
    "* OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdf7df4-7cc2-43f2-926e-14e5fbdc48f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "#!pip install transformers gradio openai diffusers accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8a4b6c-bd0b-4ba7-bc41-5351b7d29bb1",
   "metadata": {},
   "source": [
    "# Gradio Review\n",
    "\n",
    "## On your own\n",
    "Use generative AI (or not, but probably so) to help you create:\n",
    "* a gr.Blocks() interface with\n",
    "* a file upload button,\n",
    "* an (input) text box\n",
    "* an (output) text box,\n",
    "* and a submit button."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa1e02e-8ad5-4ff0-b9de-cdb555144a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "# define function that does the work\n",
    "def file_process(text_in, file_in):\n",
    "    return_msg = ''\n",
    "    \n",
    "    if file_in:\n",
    "        return_msg = 'File received'\n",
    "    else:\n",
    "        return_msg = 'File not received'\n",
    "\n",
    "    return return_msg\n",
    "\n",
    "# define the user interface\n",
    "with gr.Blocks() as demo:\n",
    "\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            file_upload = gr.File()\n",
    "            text_in = gr.Textbox(label='Query')\n",
    "        text_out = gr.TextArea(label='Response')\n",
    "    submit_btn = gr.Button(value='Submit', variant='primary')\n",
    "\n",
    "    # define the connections between the block elements and the output\n",
    "    submit_btn.click(file_process, inputs=[text_in, file_upload], outputs=[text_out])\n",
    "\n",
    "# start the program\n",
    "demo.launch(show_error=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9dbb61b-c306-4770-a1ea-9e9ebb23758e",
   "metadata": {},
   "source": [
    "# Huggingface Transformers\n",
    "* [A walk through the possibilities](https://huggingface.co/docs/transformers/index) : tasks and models available\n",
    "* [Example: Image-to-text](https://huggingface.co/Salesforce/blip-image-captioning-large)\n",
    "\n",
    "Model recommendations:\n",
    "* Companies you know\n",
    "* Model card with solid description of behavior\n",
    "* **READ THE MODEL CARD**\n",
    "* High downloads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3241e3-67b3-40ce-85f0-50338b3a7a16",
   "metadata": {},
   "source": [
    "## Using models\n",
    "Primarily: [pipelines](https://huggingface.co/docs/transformers/main_classes/pipelines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c956f3-7c38-445b-9b77-bc624a6f9ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29e10ec-60f7-456d-a96e-2978d08ed1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load document\n",
    "with open('dsminor_document.txt', 'r') as f:\n",
    "    doc = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1db003a-bab3-40c3-9501-0df20676eec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use default in pytorch\n",
    "summarizer = pipeline(\"summarization\")\n",
    "summarizer(doc, min_length=5, max_length=500, do_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9daa49ac-741e-42d8-a590-d867150f2a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use models to select a model\n",
    "falconzier = pipeline(\"summarization\", model='Falconsai/text_summarization')\n",
    "falconzier(doc, min_length=5, max_length=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a89adc3-a7f4-4c57-8b07-a786b0a188c1",
   "metadata": {},
   "source": [
    "Note: you can use config to get rid of the error above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409733f6-368e-4b2b-8fa0-61d941ebd1dc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Other times, you should just use what the model card says:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318bb916-ff58-42fc-b248-4acbada7eb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import ShapEPipeline\n",
    "from diffusers.utils import export_to_gif\n",
    "\n",
    "\n",
    "model_name = \"openai/shap-e\"\n",
    "pipe = ShapEPipeline.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d94f42-8d03-459e-8b68-512e431094a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "guidance_scale = 15.0\n",
    "prompt = \"a running dog\"\n",
    "images = pipe(\n",
    "    prompt,\n",
    "    guidance_scale=guidance_scale,\n",
    "    num_inference_steps=64,\n",
    "    frame_size=256,\n",
    ").images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d2a4b8-a56b-4e00-a4bc-c025ef0a23d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gif_path = export_to_gif(images, \"running_dog.gif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997d2f00-d387-421e-94d6-f997564276a0",
   "metadata": {},
   "source": [
    "## Relation to gradio app\n",
    "Now, let's say that we actually want to make a gradio app do this. How can we modify the app above to make this happen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd89f7a-a453-4304-86cd-90002a15c6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a65d20-24fb-4667-a644-d8bf5158a717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use default in pytorch\n",
    "summarizer = pipeline(\"summarization\")\n",
    "\n",
    "# define function that does the work\n",
    "def file_process(text_in, file_in):\n",
    "    with open(file_in, 'r') as f:\n",
    "        doc = f.read()\n",
    "        \n",
    "    return_msg = summarizer(doc, min_length=5, max_length=500, do_sample=False)[0]['summary_text']\n",
    "\n",
    "    return return_msg\n",
    "\n",
    "# define the user interface\n",
    "with gr.Blocks() as demo:\n",
    "\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            file_upload = gr.File()\n",
    "            text_in = gr.Textbox(label='Query')\n",
    "        text_out = gr.TextArea(label='Response')\n",
    "    submit_btn = gr.Button(value='Submit', variant='primary')\n",
    "\n",
    "    # define the connections between the block elements and the output\n",
    "    submit_btn.click(file_process, inputs=[text_in, file_upload], outputs=[text_out])\n",
    "\n",
    "# start the program\n",
    "demo.launch(show_error=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397b72b3-129d-4096-b788-17327eb4d3a4",
   "metadata": {},
   "source": [
    "## What happens if you don't want to download the model?\n",
    "Use [API Inference Endpoints](https://huggingface.co/docs/api-inference/index). This means that you'll need a HF token for private models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9a1a37-c0f2-4e74-9913-6394fc3fdde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee64e7c4-cd39-4e5e-92cd-3a943ce0aaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4034f5a0-1617-4fbe-b407-e2f2f7076669",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "headers = {\"Authorization\": f\"Bearer {open('/Users/bellcs1/.cache/huggingface/token').read()}\"}\n",
    "API_URL = \"https://api-inference.huggingface.co/models/facebook/bart-large-cnn\"\n",
    "\n",
    "def query(payload):\n",
    "    response = requests.post(API_URL, headers=headers, json=payload)\n",
    "    return response.json()\n",
    "\n",
    "message = {\n",
    "        \"inputs\": doc,\n",
    "        \"parameters\": {\"do_sample\": False, 'min_length':5, 'max_length':200, },\n",
    "        \"options\": {'wait_on_model': True}\n",
    "    }\n",
    "    \n",
    "response = query(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bb15cb-503d-46ac-90d5-ab3474123676",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667688cc-5d75-466f-8ce5-d42455fb161b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function that does the work\n",
    "def file_process(text_in, file_in):\n",
    "    with open(file_in, 'r') as f:\n",
    "            doc = f.read()\n",
    "    \n",
    "    message['inputs'] = doc\n",
    "    return_msg = query(message)[0]['generated_text']\n",
    "\n",
    "    return return_msg\n",
    "\n",
    "# define the user interface\n",
    "with gr.Blocks() as demo:\n",
    "\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            file_upload = gr.File()\n",
    "            text_in = gr.Textbox(label='Query')\n",
    "        text_out = gr.TextArea(label='Response')\n",
    "    submit_btn = gr.Button(value='Submit', variant='primary')\n",
    "\n",
    "    # define the connections between the block elements and the output\n",
    "    submit_btn.click(file_process, inputs=[text_in, file_upload], outputs=[text_out])\n",
    "\n",
    "# start the program\n",
    "demo.launch(show_error=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65661150-edee-40a8-9769-cb7896862707",
   "metadata": {},
   "source": [
    "# Introduction to OpenAI API\n",
    "[OpenAI API](https://platform.openai.com/docs/overview)\n",
    "\n",
    "Make sure to create your API key and **DO NOT** post it anywhere publicly. 100% you will be broke within hours!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
